{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Prompts"
      ],
      "metadata": {
        "id": "Jun0eEiwp667"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## What are prompts?"
      ],
      "metadata": {
        "id": "f8Fdsx87p8-8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Prompts are instructions or questions that guide an AI system like me in generating a response or performing a task. They help define what you're asking for or what you want the AI to do.\n",
        "\n",
        "- Essentially, prompts provide the context or direction for the AI to generate the most relevant and useful responses."
      ],
      "metadata": {
        "id": "b40LnYxRqCm0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Static Prompting"
      ],
      "metadata": {
        "id": "HuXbZOBcu0Lc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Static prompting involves using a fixed or predefined prompt that doesn't change during the interaction. The prompt remains the same each time it’s used.\n",
        "\n",
        "- This approach can work well for tasks that require consistency and a clear, straightforward output.\n",
        "\n",
        "    - Example: Asking an AI, \"What is the capital of France?\" every time you want to know the capital of France, with no variation in the way the question is phrased.\n",
        "\n",
        "- Characteristics of Static Prompting:\n",
        "\n",
        "    - Predictable: The same prompt leads to the same or similar response each time.\n",
        "\n",
        "    - Simple and direct: Often used when the task is straightforward and doesn't need much variation.\n",
        "\n",
        "    - Less adaptable: It doesn't change based on the context or flow of the conversation."
      ],
      "metadata": {
        "id": "n7Gnspphu1fS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dynamic Prompting"
      ],
      "metadata": {
        "id": "-aW5Lz__vSfs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Dynamic prompting, involves prompts that change depending on the context or the flow of the interaction. The AI can adapt and modify its responses based on previous interactions, user input, or the evolving situation.\n",
        "\n",
        "- In dynamic prompting, the prompt may vary or evolve in real-time to accommodate new information.\n",
        "\n",
        "    - Example: Instead of always asking \"What is the capital of France?\" you might first ask, \"Tell me about France,\" then based on the response, ask more specific follow-up questions like, \"What is the capital?\" or \"Tell me about the culture there.\"\n",
        "\n",
        "- Characteristics of Dynamic Prompting:\n",
        "\n",
        "    - Context-sensitive: The prompt can change in response to the situation or previous answers.\n",
        "\n",
        "    - Flexible: It allows for more personalized, varied, and nuanced responses.\n",
        "\n",
        "    - More complex: Dynamic prompting requires the system to track conversation history or adjust its focus based on input."
      ],
      "metadata": {
        "id": "_psqhUnCvaCl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Code"
      ],
      "metadata": {
        "id": "0IDMi1uTv9a2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import PromptTemplate\n",
        "\n",
        "# template\n",
        "template = PromptTemplate(\n",
        "    template=\"\"\"\n",
        "Please summarize the research paper titled \"{paper_input}\" with the following specifications:\n",
        "Explanation Style: {style_input}\n",
        "Explanation Length: {length_input}\n",
        "1. Mathematical Details:\n",
        "   - Include relevant mathematical equations if present in the paper.\n",
        "   - Explain the mathematical concepts using simple, intuitive code snippets where applicable.\n",
        "2. Analogies:\n",
        "   - Use relatable analogies to simplify complex ideas.\n",
        "If certain information is not available in the paper, respond with: \"Insufficient information available\" instead of guessing.\n",
        "Ensure the summary is clear, accurate, and aligned with the provided style and length.\n",
        "\"\"\",\n",
        "input_variables=['paper_input', 'style_input','length_input'],\n",
        "validate_template=True\n",
        ")\n",
        "\n",
        "template.save('template.json')"
      ],
      "metadata": {
        "id": "qogljBrM1l4T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# .json\n",
        "\n",
        "{\n",
        "    \"name\": null,\n",
        "    \"input_variables\": [\n",
        "        \"length_input\",\n",
        "        \"paper_input\",\n",
        "        \"style_input\"\n",
        "    ],\n",
        "    \"optional_variables\": [],\n",
        "    \"output_parser\": null,\n",
        "    \"partial_variables\": {},\n",
        "    \"metadata\": null,\n",
        "    \"tags\": null,\n",
        "    \"template\": \"\\nPlease summarize the research paper titled \\\"{paper_input}\\\" with the following specifications:\\nExplanation Style: {style_input}  \\nExplanation Length: {length_input}  \\n1. Mathematical Details:  \\n   - Include relevant mathematical equations if present in the paper.  \\n   - Explain the mathematical concepts using simple, intuitive code snippets where applicable.  \\n2. Analogies:  \\n   - Use relatable analogies to simplify complex ideas.  \\nIf certain information is not available in the paper, respond with: \\\"Insufficient information available\\\" instead of guessing.  \\nEnsure the summary is clear, accurate, and aligned with the provided style and length.\\n\",\n",
        "    \"template_format\": \"f-string\",\n",
        "    \"validate_template\": true,\n",
        "    \"_type\": \"prompt\"\n",
        "}"
      ],
      "metadata": {
        "id": "rloTjwcZwTcw"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from dotenv import load_dotenv\n",
        "import streamlit as st\n",
        "from langchain_core.prompts import PromptTemplate,load_prompt\n",
        "\n",
        "load_dotenv()\n",
        "model = ChatOpenAI()\n",
        "\n",
        "st.header('Reasearch Tool')\n",
        "\n",
        "paper_input = st.selectbox( \"Select Research Paper Name\", [\"Attention Is All You Need\", \"BERT: Pre-training of Deep Bidirectional Transformers\", \"GPT-3: Language Models are Few-Shot Learners\", \"Diffusion Models Beat GANs on Image Synthesis\"] )\n",
        "\n",
        "style_input = st.selectbox( \"Select Explanation Style\", [\"Beginner-Friendly\", \"Technical\", \"Code-Oriented\", \"Mathematical\"] )\n",
        "\n",
        "length_input = st.selectbox( \"Select Explanation Length\", [\"Short (1-2 paragraphs)\", \"Medium (3-5 paragraphs)\", \"Long (detailed explanation)\"] )\n",
        "\n",
        "template = load_prompt('template.json')\n",
        "\n",
        "\n",
        "\n",
        "if st.button('Summarize'):\n",
        "    chain = template | model\n",
        "    result = chain.invoke({\n",
        "        'paper_input':paper_input,\n",
        "        'style_input':style_input,\n",
        "        'length_input':length_input\n",
        "    })\n",
        "    st.write(result.content)"
      ],
      "metadata": {
        "id": "8M91yvGJwBnk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prompt templates"
      ],
      "metadata": {
        "id": "9iIe1l0GxNfT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Prompt templates are predefined structures or frameworks for crafting prompts, which can help guide an AI to generate consistent and relevant responses for a variety of tasks. These templates typically include placeholders or variables that can be customized based on the user's needs, allowing for efficient and tailored interactions.\n",
        "\n",
        "- Using prompt templates can help ensure that the AI's output is focused, accurate, and aligned with the user's goals."
      ],
      "metadata": {
        "id": "f27u-aK0xPNM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Why use Prompt templates ?\n",
        "\n",
        "1. Consistency\n",
        "  - Why it matters: When you need the same type of response multiple times (e.g., generating summaries or writing reports), prompt templates ensure that the format and structure remain consistent.\n",
        "\n",
        "    - Example: If you're using AI to write product descriptions, a prompt template can help you get the same structure (e.g., product features, benefits, and specifications) every time.\n",
        "\n",
        "2. Efficiency\n",
        "  - Why it matters: Crafting a well-formed prompt from scratch each time can be time-consuming. A template allows you to quickly generate effective prompts without rethinking every detail.\n",
        "\n",
        "    - Example: If you need a comparison between two products, a template like \"Compare [product 1] and [product 2] based on [criteria]\" saves time compared to coming up with a new phrasing for each comparison.\n",
        "\n",
        "3. Clarity\n",
        "  - Why it matters: Templates help make your prompts clearer by breaking down complex requests into a structured format, ensuring that you don’t miss key information or get too vague.\n",
        "\n",
        "    - Example: A template like \"Summarize this article in [number] of sentences\" clearly indicates the output you want, minimizing confusion about what you're asking.\n",
        "\n",
        "4. Customization\n",
        "  - Why it matters: Templates provide a starting point, but you can easily customize the placeholders based on your specific needs. This allows for flexibility while maintaining structure.\n",
        "\n",
        "    - Example: A template like \"Write a [type of content] about [topic] with a focus on [specific aspect]\" can be adapted to fit different writing tasks (e.g., blog posts, product reviews, etc.), while ensuring the response stays relevant to your goals.\n",
        "\n",
        "5. Avoiding Redundancy\n",
        "  - Why it matters: With templates, you don’t have to keep repeating the same instructions each time you want to generate similar responses. The template handles the basic structure, allowing you to focus only on what's unique in each request.\n",
        "\n",
        "    - Example: If you're regularly asking for advice on various topics, a template like \"Give me advice on [topic] considering [specific factor]\" saves you from re-explaining the context every time.\n",
        "\n",
        "6. Better Focused Outputs\n",
        "  - Why it matters: Templates guide the AI to focus on the relevant parts of a task, helping it stay on track and produce outputs that directly align with your needs.\n",
        "\n",
        "    - Example: Instead of asking, \"Tell me about World War II,\" a more structured prompt like \"Provide a summary of World War II's impact on global politics\" will produce a more focused response that addresses the specific aspect you're interested in.\n",
        "\n",
        "7. Error Reduction\n",
        "  - Why it matters: A well-structured template reduces the chances of miscommunication or ambiguity in your prompt, leading to more accurate and useful responses from the AI.\n",
        "\n",
        "    - Example: If you always use a template like \"List the [number] key features of [product] with their benefits,\" it helps avoid vague answers, ensuring the response covers both features and benefits in a clear manner.\n",
        "\n",
        "8. Streamlining Collaboration\n",
        "  - Why it matters: If you're working with a team, using templates ensures everyone is using the same approach and phrasing when interacting with the AI. This creates uniformity across projects or tasks.\n",
        "\n",
        "    - Example: If your team is using AI to draft reports, a template like \"Create an executive summary of the report focusing on [key points]\" ensures all summaries have the same tone, structure, and content focus.\n",
        "\n",
        "9. Improved Creativity and Quality\n",
        "  - Why it matters: When you're working on tasks like creative writing or brainstorming, templates help spark ideas by giving you a starting framework. They help you explore different angles without having to start from scratch each time.\n",
        "\n",
        "    - Example: A creative writing template like \"Write a [genre] story about [character] encountering [conflict]\" can push you to explore different scenarios or challenges, encouraging creativity while keeping the story focused."
      ],
      "metadata": {
        "id": "a1TEO_VsxQGr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_openai import ChatOpenAI\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "model = ChatOpenAI()\n",
        "\n",
        "# detailed way\n",
        "template2 = PromptTemplate(\n",
        "    template='Greet this person in 5 languages. The name of the person is {name}',\n",
        "    input_variables=['name']\n",
        ")\n",
        "\n",
        "# fill the values of the placeholders\n",
        "prompt = template2.invoke({'name':'sneh'})\n",
        "\n",
        "result = model.invoke(prompt)\n",
        "\n",
        "print(result.content)\n"
      ],
      "metadata": {
        "id": "CmIladv81xke"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "model = ChatOpenAI()\n",
        "\n",
        "chat_history = [\n",
        "    SystemMessage(content='You are a helpful AI assistant')\n",
        "]\n",
        "\n",
        "while True:\n",
        "    user_input = input('You: ')\n",
        "    chat_history.append(HumanMessage(content=user_input))\n",
        "    if user_input == 'exit':\n",
        "        break\n",
        "    result = model.invoke(chat_history)\n",
        "    chat_history.append(AIMessage(content=result.content))\n",
        "    print(\"AI: \",result.content)\n",
        "\n",
        "print(chat_history)"
      ],
      "metadata": {
        "id": "evrgPzRs2jJv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage\n",
        "from langchain_openai import ChatOpenAI\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "model = ChatOpenAI()\n",
        "\n",
        "messages=[\n",
        "    SystemMessage(content='You are a helpful assistant'),\n",
        "    HumanMessage(content='Tell me about LangChain')\n",
        "]\n",
        "\n",
        "result = model.invoke(messages)\n",
        "\n",
        "messages.append(AIMessage(content=result.content))\n",
        "\n",
        "print(messages)\n"
      ],
      "metadata": {
        "id": "a1fjx2ip3QTy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chat Prompt Template"
      ],
      "metadata": {
        "id": "dT3f3DDO3y6b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Chat prompt templates are structured formats used to guide and streamline conversations between humans and AI systems. These templates help ensure that the AI understands the user’s intent clearly and responds in an effective, contextually appropriate manner.\n",
        "\n",
        "1. Purpose and Use Cases\n",
        "- Consistency: Templates help maintain consistency in interactions, ensuring responses remain relevant and accurate.\n",
        "\n",
        "- Efficiency: By guiding users with predefined structures, templates allow users to save time and effort in formulating prompts.\n",
        "\n",
        "- Clarification: Templates can help clarify ambiguous or complex questions, providing more detailed and specific prompts that yield more accurate answers.\n",
        "\n",
        "2. Core Components of a Prompt Template\n",
        "- A good prompt template includes specific sections to structure the query.\n",
        "\n",
        "- Context: Any background information that helps the AI understand the situation or user’s request. This could be previous conversation history or additional context to a question.\n",
        "\n",
        "- Instruction: Clear guidance on what the user expects the AI to do. This is the action the AI needs to take (e.g., \"explain\", \"recommend\", \"create\", etc.).\n",
        "\n",
        "- Constraints: Any limitations or boundaries the response should follow (e.g., \"respond in 100 words,\" \"use simple language,\" \"provide examples\").\n",
        "\n",
        "- Details: Additional specifics or data that the AI needs to incorporate to answer the question properly.\n",
        "\n",
        "3. Examples of Chat Prompt Templates\n",
        "- General Inquiry:\n",
        "\n",
        " \"Can you [action] [specific task], considering [context]?\"\n",
        "\n",
        "    - Example: \"Can you recommend a good sci-fi novel, considering that I liked Dune and Ender's Game?\"\n",
        "\n",
        "- Clarification Requests:\n",
        "\n",
        " \"What do you mean by [term or concept] in the context of [related topic]?\"\n",
        "\n",
        "    - Example: \"What do you mean by 'machine learning' in the context of artificial intelligence?\"\n",
        "\n",
        "- Problem-Solving:\n",
        "\n",
        " \"How can I [solve a problem] given [constraints or context]?\"\n",
        "\n",
        "    - Example: \"How can I improve the SEO of my website given a budget of $500?\"\n",
        "\n",
        "- Task Automation/Action Requests:\n",
        "\n",
        " \"Please help me [perform a task] by [giving step-by-step instructions].\"\n",
        "\n",
        "    - Example: \"Please help me draft a professional email to request time off from work.\"\n",
        "\n",
        "- Creative Prompts:\n",
        "\n",
        " \"Generate a [story/poem/idea] that is [describe theme/genre/style].\"\n",
        "\n",
        "    - Example: \"Generate a short story that involves time travel, with a mystery plot.\"\n",
        "\n",
        "4. Theoretical Benefits\n",
        "- User Clarity: Prompt templates can help users clarify their thoughts and organize what they want from the AI, improving the overall quality of interactions.\n",
        "\n",
        "- AI Understanding: By using structured templates, users ensure that they provide all necessary information, allowing the AI to provide more accurate and contextually rich responses.\n",
        "\n",
        "- Reduction of Ambiguity: Templates reduce the risk of misunderstandings between the user and AI by minimizing ambiguity in the prompt.\n",
        "\n",
        "- Adaptive Learning: For advanced AI systems, using templates may help in learning and fine-tuning responses, enhancing overall performance over time.\n",
        "\n",
        "5. Challenges\n",
        "- Over-Specification: Templates may sometimes lead to overly rigid queries, potentially limiting creativity or flexibility in responses.\n",
        "\n",
        "- User Frustration: For inexperienced users, templates might feel restrictive, especially when they are trying to phrase their queries more casually or informally.\n",
        "\n",
        "- Overfitting: AI systems may become overly reliant on certain templates, which might affect their ability to handle queries outside of those structures.\n",
        "\n",
        "\n",
        "\n",
        "**By using prompt templates, both the user and AI can align more effectively, optimizing communication for better outcomes.**"
      ],
      "metadata": {
        "id": "56RIraCl30p2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "chat_template = ChatPromptTemplate([\n",
        "    ('system', 'You are a helpful {domain} expert'),\n",
        "    ('human', 'Explain in simple terms, what is {topic}')\n",
        "])\n",
        "\n",
        "prompt = chat_template.invoke({'domain':'cricket','topic':'Dusra'})\n",
        "\n",
        "print(prompt)"
      ],
      "metadata": {
        "id": "YBtAwL--4zKc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Message Placeholder"
      ],
      "metadata": {
        "id": "5zRRzZdl5e5Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Langchain, a \"message placeholder\" typically refers to the use of variables or placeholders within messages to dynamically fill in content when interacting with language models or chains.\n",
        "\n",
        "- Langchain is a framework that allows you to build complex workflows using language models. A message placeholder might be used in scenarios like chatbots, workflows, or other dynamic message generation systems where the message content is dependent on specific variables or context.\n",
        "\n",
        "- You can use placeholders to insert dynamic data into a message, such as user inputs or other computed values.\n",
        "\n"
      ],
      "metadata": {
        "id": "RnkRUmej5h2q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "# chat template\n",
        "chat_template = ChatPromptTemplate([\n",
        "    ('system','You are a helpful customer support agent'),\n",
        "    MessagesPlaceholder(variable_name='chat_history'),\n",
        "    ('human','{query}')\n",
        "])\n",
        "\n",
        "chat_history = []\n",
        "# load chat history\n",
        "with open('chat_history.txt') as f:\n",
        "    chat_history.extend(f.readlines())\n",
        "\n",
        "print(chat_history)\n",
        "\n",
        "# create prompt\n",
        "prompt = chat_template.invoke({'chat_history':chat_history, 'query':'Where is my refund'})\n",
        "\n",
        "print(prompt)"
      ],
      "metadata": {
        "id": "KL1G_Sg253Pl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
