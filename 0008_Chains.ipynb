{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Chains"
      ],
      "metadata": {
        "id": "n4EGmTE6K19C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- In LangChain, a \"chain\" refers to a sequence of calls, whether to language models (LLMs), external tools, or data preprocessing steps. It's a way to combine different components and functionalities in a logical order to create more complex and powerful applications."
      ],
      "metadata": {
        "id": "fE4ZCvI6Kz7H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Simple Chain"
      ],
      "metadata": {
        "id": "w4iYRZeXKz6s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Simple chain where the outputs of one step feed directly into next."
      ],
      "metadata": {
        "id": "9aAuACxyKz2E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-2.0-flash-001\",\n",
        "    temperature=0,\n",
        "    max_tokens=None,\n",
        "    timeout=None,\n",
        "    max_retries=2,\n",
        "    api_key = \"AIzaSyDCnnYyMnnwleE0jeyN-NKFb-aphjSi5WM\"\n",
        ")\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    template='Generate 5 interesting facts about {topic}',\n",
        "    input_variables=['topic']\n",
        ")\n",
        "\n",
        "parser = StrOutputParser()\n",
        "\n",
        "chain = prompt | llm | parser\n",
        "\n",
        "result = chain.invoke({'topic':'cricket'})\n",
        "\n",
        "print(result)\n",
        "\n",
        "chain.get_graph().print_ascii()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yYCaeYO_LUo2",
        "outputId": "880fcd70-dd86-40c1-bf63-875333f7b626"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Okay, here are 5 interesting facts about cricket that you might not know:\n",
            "\n",
            "1.  **The Longest Cricket Match Lasted 12 Days:** A timeless Test match between England and South Africa in Durban in 1939 went on for 12 days (with a rest day in between). It was eventually declared a draw because the English team had to catch their boat home!\n",
            "\n",
            "2.  **Cricket Balls Used to be Stuffed with Feathers:**  Early cricket balls, dating back to the 18th century, were literally stuffed with feathers and then covered in leather. This made them unpredictable and likely quite painful to be hit by!\n",
            "\n",
            "3.  **The \"Cow Corner\" is Named After Actual Cows:** The fielding position known as \"Cow Corner\" got its name because it was often the area where agricultural workers would graze their cows during village cricket matches.  A shot hit in that direction was considered a risky, agricultural-style slog.\n",
            "\n",
            "4.  **Cricket is the Second Most Popular Sport in the World:**  While it might not be as globally ubiquitous as football (soccer), cricket boasts a massive following, particularly in India, Pakistan, Australia, England, and the West Indies. It's estimated to have over 2.5 billion fans worldwide.\n",
            "\n",
            "5.  **A \"Duck\" Isn't Named After the Bird:**  The term \"duck\" for a score of zero is believed to have originated from the shape of a duck's egg, which resembles the number zero. Another theory suggests it comes from the phrase \"duck's egg,\" used to describe a bad score in earlier forms of cricket.\n",
            "      +-------------+      \n",
            "      | PromptInput |      \n",
            "      +-------------+      \n",
            "             *             \n",
            "             *             \n",
            "             *             \n",
            "    +----------------+     \n",
            "    | PromptTemplate |     \n",
            "    +----------------+     \n",
            "             *             \n",
            "             *             \n",
            "             *             \n",
            "+------------------------+ \n",
            "| ChatGoogleGenerativeAI | \n",
            "+------------------------+ \n",
            "             *             \n",
            "             *             \n",
            "             *             \n",
            "    +-----------------+    \n",
            "    | StrOutputParser |    \n",
            "    +-----------------+    \n",
            "             *             \n",
            "             *             \n",
            "             *             \n",
            "+-----------------------+  \n",
            "| StrOutputParserOutput |  \n",
            "+-----------------------+  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SequentialChain"
      ],
      "metadata": {
        "id": "_haapujlKz1r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Chain where the outputs of one chain feed directly into next."
      ],
      "metadata": {
        "id": "TSDzGN7dKzxC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-2.0-flash-001\",\n",
        "    temperature=0,\n",
        "    max_tokens=None,\n",
        "    timeout=None,\n",
        "    max_retries=2,\n",
        "    api_key = \"AIzaSyDCnnYyMnnwleE0jeyN-NKFb-aphjSi5WM\"\n",
        ")\n",
        "\n",
        "prompt1 = PromptTemplate(\n",
        "    template='Generate a detailed report on {topic}',\n",
        "    input_variables=['topic']\n",
        ")\n",
        "\n",
        "prompt2 = PromptTemplate(\n",
        "    template='Generate a 5 pointer summary from the following text \\n {text}',\n",
        "    input_variables=['text']\n",
        ")\n",
        "\n",
        "parser = StrOutputParser()\n",
        "\n",
        "chain = prompt1 | llm | parser | prompt2 | llm | parser\n",
        "\n",
        "result = chain.invoke({'topic': 'Unemployment in India'})\n",
        "\n",
        "print(result)\n",
        "\n",
        "chain.get_graph().print_ascii()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ifrl1_lNCQk",
        "outputId": "c05bf7b6-e3a9-4ff9-f7e6-7de82f757362"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here's a 5-point summary of the provided text on unemployment in India:\n",
            "\n",
            "*   **Complex Issue:** Unemployment in India is multifaceted, characterized by a large informal sector, underemployment, and regional/demographic disparities, masking the true extent of the problem despite relatively low official rates.\n",
            "\n",
            "*   **Key Trends:** While overall unemployment rates fluctuate, urban areas, women, and educated youth face higher rates. The COVID-19 pandemic significantly worsened the situation.\n",
            "\n",
            "*   **Root Causes:** Slow economic growth, a large but under-skilled workforce, skill gaps, rigid labor laws, and social barriers contribute to unemployment.\n",
            "\n",
            "*   **Consequences are Severe:** Unemployment leads to reduced economic output, increased poverty, social unrest, health issues, and potential political instability.\n",
            "\n",
            "*   **Multi-Pronged Solutions Needed:** Addressing unemployment requires sustainable economic growth, investment in education and skills, labor law reforms, entrepreneurship promotion, formalizing the informal sector, empowering women, and improved data collection.\n",
            "      +-------------+      \n",
            "      | PromptInput |      \n",
            "      +-------------+      \n",
            "             *             \n",
            "             *             \n",
            "             *             \n",
            "    +----------------+     \n",
            "    | PromptTemplate |     \n",
            "    +----------------+     \n",
            "             *             \n",
            "             *             \n",
            "             *             \n",
            "+------------------------+ \n",
            "| ChatGoogleGenerativeAI | \n",
            "+------------------------+ \n",
            "             *             \n",
            "             *             \n",
            "             *             \n",
            "    +-----------------+    \n",
            "    | StrOutputParser |    \n",
            "    +-----------------+    \n",
            "             *             \n",
            "             *             \n",
            "             *             \n",
            "+-----------------------+  \n",
            "| StrOutputParserOutput |  \n",
            "+-----------------------+  \n",
            "             *             \n",
            "             *             \n",
            "             *             \n",
            "    +----------------+     \n",
            "    | PromptTemplate |     \n",
            "    +----------------+     \n",
            "             *             \n",
            "             *             \n",
            "             *             \n",
            "+------------------------+ \n",
            "| ChatGoogleGenerativeAI | \n",
            "+------------------------+ \n",
            "             *             \n",
            "             *             \n",
            "             *             \n",
            "    +-----------------+    \n",
            "    | StrOutputParser |    \n",
            "    +-----------------+    \n",
            "             *             \n",
            "             *             \n",
            "             *             \n",
            "+-----------------------+  \n",
            "| StrOutputParserOutput |  \n",
            "+-----------------------+  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RunnableParallel"
      ],
      "metadata": {
        "id": "Ge1mUabMKzwd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain.schema.runnable import RunnableParallel\n",
        "\n",
        "\n",
        "llm1 = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-2.0-flash-001\",\n",
        "    temperature=0,\n",
        "    max_tokens=None,\n",
        "    timeout=None,\n",
        "    max_retries=2,\n",
        "    api_key = \"AIzaSyDCnnYyMnnwleE0jeyN-NKFb-aphjSi5WM\"\n",
        ")\n",
        "\n",
        "llm2 = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-2.0-flash-001\",\n",
        "    temperature=0,\n",
        "    max_tokens=None,\n",
        "    timeout=None,\n",
        "    max_retries=2,\n",
        "    api_key = \"AIzaSyDCnnYyMnnwleE0jeyN-NKFb-aphjSi5WM\"\n",
        ")\n",
        "\n",
        "prompt1 = PromptTemplate(\n",
        "    template='Generate short and simple notes from the following text \\n {text}',\n",
        "    input_variables=['text']\n",
        ")\n",
        "\n",
        "prompt2 = PromptTemplate(\n",
        "    template='Generate 5 short question answers from the following text \\n {text}',\n",
        "    input_variables=['text']\n",
        ")\n",
        "\n",
        "prompt3 = PromptTemplate(\n",
        "    template='Merge the provided notes and quiz into a single document \\n notes -> {notes} and quiz -> {quiz}',\n",
        "    input_variables=['notes', 'quiz']\n",
        ")\n",
        "\n",
        "parser = StrOutputParser()\n",
        "\n",
        "parallel_chain = RunnableParallel({\n",
        "    'notes': prompt1 | llm1 | parser,\n",
        "    'quiz': prompt2 | llm2 | parser\n",
        "})\n",
        "\n",
        "merge_chain = prompt3 | llm1 | parser\n",
        "\n",
        "chain = parallel_chain | merge_chain\n",
        "\n",
        "text = \"\"\"\n",
        "Support vector machines (SVMs) are a set of supervised learning methods used for classification, regression and outliers detection.\n",
        "\n",
        "The advantages of support vector machines are:\n",
        "\n",
        "Effective in high dimensional spaces.\n",
        "\n",
        "Still effective in cases where number of dimensions is greater than the number of samples.\n",
        "\n",
        "Uses a subset of training points in the decision function (called support vectors), so it is also memory efficient.\n",
        "\n",
        "Versatile: different Kernel functions can be specified for the decision function. Common kernels are provided, but it is also possible to specify custom kernels.\n",
        "\n",
        "The disadvantages of support vector machines include:\n",
        "\n",
        "If the number of features is much greater than the number of samples, avoid over-fitting in choosing Kernel functions and regularization term is crucial.\n",
        "\n",
        "SVMs do not directly provide probability estimates, these are calculated using an expensive five-fold cross-validation (see Scores and probabilities, below).\n",
        "\n",
        "The support vector machines in scikit-learn support both dense (numpy.ndarray and convertible to that by numpy.asarray) and sparse (any scipy.sparse) sample vectors as input. However, to use an SVM to make predictions for sparse data, it must have been fit on such data. For optimal performance, use C-ordered numpy.ndarray (dense) or scipy.sparse.csr_matrix (sparse) with dtype=float64.\n",
        "\"\"\"\n",
        "\n",
        "result = chain.invoke({'text':text})\n",
        "\n",
        "print(result)\n",
        "\n",
        "chain.get_graph().print_ascii()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qzPOdBdxOPEF",
        "outputId": "9c44ef8a-f975-415c-cf28-cb48f6fe284d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# Support Vector Machines (SVMs): Notes and Quiz\n",
            "\n",
            "This document combines notes on Support Vector Machines (SVMs) with a short quiz to test understanding.\n",
            "\n",
            "## SVM Notes\n",
            "\n",
            "**Definition:** Supervised learning methods for classification, regression, and outlier detection.\n",
            "\n",
            "**Advantages:**\n",
            "\n",
            "*   Effective in high-dimensional spaces.\n",
            "*   Works well even when dimensions > samples.\n",
            "*   Memory efficient (uses \"support vectors\").\n",
            "*   Versatile: Customizable kernel functions.\n",
            "\n",
            "**Disadvantages:**\n",
            "\n",
            "*   Overfitting risk if features >> samples (kernel/regularization tuning needed).\n",
            "*   Probability estimates are computationally expensive.\n",
            "\n",
            "**Implementation Notes (scikit-learn):**\n",
            "\n",
            "*   Supports dense (NumPy arrays) and sparse (SciPy sparse matrices) data.\n",
            "*   Fit model on data type used for prediction.\n",
            "*   Optimal performance: C-ordered NumPy arrays (dense) or CSR sparse matrices (sparse) with `dtype=float64`.\n",
            "\n",
            "## SVM Quiz\n",
            "\n",
            "**1. Question:** What are SVMs used for?\n",
            "   **Answer:** Classification, regression, and outliers detection.\n",
            "\n",
            "**2. Question:** What is an advantage of SVMs in high dimensional spaces?\n",
            "   **Answer:** They are effective.\n",
            "\n",
            "**3. Question:** What makes SVMs memory efficient?\n",
            "   **Answer:** They use a subset of training points called support vectors.\n",
            "\n",
            "**4. Question:** What is a disadvantage of SVMs when the number of features is much greater than the number of samples?\n",
            "   **Answer:** Avoiding over-fitting in choosing Kernel functions and regularization term is crucial.\n",
            "\n",
            "**5. Question:** What type of sample vectors do support vector machines in scikit-learn support?\n",
            "   **Answer:** Dense and sparse sample vectors.\n",
            "                    +---------------------------+                      \n",
            "                    | Parallel<notes,quiz>Input |                      \n",
            "                    +---------------------------+                      \n",
            "                       ***                   ***                       \n",
            "                   ****                         ****                   \n",
            "                 **                                 **                 \n",
            "    +----------------+                          +----------------+     \n",
            "    | PromptTemplate |                          | PromptTemplate |     \n",
            "    +----------------+                          +----------------+     \n",
            "             *                                           *             \n",
            "             *                                           *             \n",
            "             *                                           *             \n",
            "+------------------------+                  +------------------------+ \n",
            "| ChatGoogleGenerativeAI |                  | ChatGoogleGenerativeAI | \n",
            "+------------------------+                  +------------------------+ \n",
            "             *                                           *             \n",
            "             *                                           *             \n",
            "             *                                           *             \n",
            "    +-----------------+                         +-----------------+    \n",
            "    | StrOutputParser |                         | StrOutputParser |    \n",
            "    +-----------------+                         +-----------------+    \n",
            "                       ***                   ***                       \n",
            "                          ****           ****                          \n",
            "                              **       **                              \n",
            "                    +----------------------------+                     \n",
            "                    | Parallel<notes,quiz>Output |                     \n",
            "                    +----------------------------+                     \n",
            "                                   *                                   \n",
            "                                   *                                   \n",
            "                                   *                                   \n",
            "                          +----------------+                           \n",
            "                          | PromptTemplate |                           \n",
            "                          +----------------+                           \n",
            "                                   *                                   \n",
            "                                   *                                   \n",
            "                                   *                                   \n",
            "                      +------------------------+                       \n",
            "                      | ChatGoogleGenerativeAI |                       \n",
            "                      +------------------------+                       \n",
            "                                   *                                   \n",
            "                                   *                                   \n",
            "                                   *                                   \n",
            "                          +-----------------+                          \n",
            "                          | StrOutputParser |                          \n",
            "                          +-----------------+                          \n",
            "                                   *                                   \n",
            "                                   *                                   \n",
            "                                   *                                   \n",
            "                      +-----------------------+                        \n",
            "                      | StrOutputParserOutput |                        \n",
            "                      +-----------------------+                        \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ConditionalChain"
      ],
      "metadata": {
        "id": "IVHFjvqqP08_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain.schema.runnable import RunnableParallel, RunnableBranch, RunnableLambda\n",
        "from langchain_core.output_parsers import PydanticOutputParser\n",
        "from pydantic import BaseModel, Field\n",
        "from typing import Literal\n",
        "\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-2.0-flash-001\",\n",
        "    temperature=0,\n",
        "    max_tokens=None,\n",
        "    timeout=None,\n",
        "    max_retries=2,\n",
        "    api_key = \"AIzaSyDCnnYyMnnwleE0jeyN-NKFb-aphjSi5WM\"\n",
        ")\n",
        "\n",
        "parser = StrOutputParser()\n",
        "\n",
        "class Feedback(BaseModel):\n",
        "\n",
        "    sentiment: Literal['positive', 'negative'] = Field(description='Give the sentiment of the feedback')\n",
        "\n",
        "parser2 = PydanticOutputParser(pydantic_object=Feedback)\n",
        "\n",
        "prompt1 = PromptTemplate(\n",
        "    template='Classify the sentiment of the following feedback text into postive or negative \\n {feedback} \\n {format_instruction}',\n",
        "    input_variables=['feedback'],\n",
        "    partial_variables={'format_instruction':parser2.get_format_instructions()}\n",
        ")\n",
        "\n",
        "classifier_chain = prompt1 | llm | parser2\n",
        "\n",
        "prompt2 = PromptTemplate(\n",
        "    template='Write an appropriate response to this positive feedback \\n {feedback}',\n",
        "    input_variables=['feedback']\n",
        ")\n",
        "\n",
        "prompt3 = PromptTemplate(\n",
        "    template='Write an appropriate response to this negative feedback \\n {feedback}',\n",
        "    input_variables=['feedback']\n",
        ")\n",
        "\n",
        "branch_chain = RunnableBranch(\n",
        "    (lambda x:x.sentiment == 'positive', prompt2 | llm | parser),\n",
        "    (lambda x:x.sentiment == 'negative', prompt3 | llm | parser),\n",
        "    RunnableLambda(lambda x: \"could not find sentiment\")\n",
        ")\n",
        "\n",
        "chain = classifier_chain | branch_chain\n",
        "\n",
        "print(chain.invoke({'feedback': 'This is a beautiful phone'}))\n",
        "\n",
        "chain.get_graph().print_ascii()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ylAljXSSOvpU",
        "outputId": "3b1f5886-bb78-430c-a66d-54aaecbf1482"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Okay, to respond to positive feedback, I need a little more context!  To give you the *best* response, tell me:\n",
            "\n",
            "*   **What was the feedback about?** (e.g., a product, a service, a presentation, a piece of writing, a performance, etc.)\n",
            "*   **Who is the feedback from?** (e.g., a customer, a boss, a colleague, a friend, the general public)\n",
            "*   **What was the specific positive comment?** (Even a short summary helps!)\n",
            "\n",
            "However, here are a few general responses you can adapt, depending on the situation:\n",
            "\n",
            "**General Responses:**\n",
            "\n",
            "*   \"Thank you so much for your positive feedback! I really appreciate you taking the time to share your thoughts.\"\n",
            "*   \"I'm so glad to hear you had a positive experience. We really value your feedback.\"\n",
            "*   \"Thank you! It's great to know that you were happy with [the product/service/etc.].\"\n",
            "*   \"I'm delighted to hear that! We strive to [mention what you strive for, e.g., provide excellent service, create high-quality products, etc.].\"\n",
            "\n",
            "**More Specific Responses (Examples - adapt to your situation):**\n",
            "\n",
            "*   **If the feedback was about a product:** \"Thank you! We're thrilled you're enjoying the [product name]. We put a lot of effort into [mention a key feature or benefit].\"\n",
            "*   **If the feedback was about a service:** \"Thank you for your kind words! We're committed to providing excellent service, and it's rewarding to know we're meeting your expectations.\"\n",
            "*   **If the feedback was about a presentation:** \"Thank you! I'm glad you found the presentation informative and engaging. I appreciate you letting me know.\"\n",
            "*   **If the feedback was from a boss/colleague:** \"Thank you! I appreciate the feedback. I'm always looking for ways to improve, so it's helpful to know what's working well.\"\n",
            "\n",
            "**Key things to include in your response:**\n",
            "\n",
            "*   **Express gratitude:** Say \"thank you.\"\n",
            "*   **Acknowledge the feedback:** Show that you've read and understood the comment.\n",
            "*   **(Optional) Briefly explain why you're happy to receive the feedback:** This adds a personal touch.\n",
            "*   **(Optional) If appropriate, mention future improvements or continued efforts:** This shows you're committed to maintaining or improving quality.\n",
            "\n",
            "**Example using the above information:**\n",
            "\n",
            "Let's say the feedback was:\n",
            "\n",
            "*   **About:** A customer service interaction\n",
            "*   **From:** A customer\n",
            "*   **Specific comment:** \"The customer service representative was extremely helpful and resolved my issue quickly!\"\n",
            "\n",
            "A good response would be:\n",
            "\n",
            "\"Thank you so much for your positive feedback! I'm so glad to hear that our customer service representative was able to resolve your issue quickly and efficiently. We strive to provide excellent customer service, and it's rewarding to know we're meeting your expectations. We'll be sure to pass your kind words along to the representative.\"\n",
            "\n",
            "**Give me more details, and I can give you an even better response!**\n",
            "      +-------------+      \n",
            "      | PromptInput |      \n",
            "      +-------------+      \n",
            "             *             \n",
            "             *             \n",
            "             *             \n",
            "    +----------------+     \n",
            "    | PromptTemplate |     \n",
            "    +----------------+     \n",
            "             *             \n",
            "             *             \n",
            "             *             \n",
            "+------------------------+ \n",
            "| ChatGoogleGenerativeAI | \n",
            "+------------------------+ \n",
            "             *             \n",
            "             *             \n",
            "             *             \n",
            " +----------------------+  \n",
            " | PydanticOutputParser |  \n",
            " +----------------------+  \n",
            "             *             \n",
            "             *             \n",
            "             *             \n",
            "        +--------+         \n",
            "        | Branch |         \n",
            "        +--------+         \n",
            "             *             \n",
            "             *             \n",
            "             *             \n",
            "     +--------------+      \n",
            "     | BranchOutput |      \n",
            "     +--------------+      \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "awQ2EgdxPe5A"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}